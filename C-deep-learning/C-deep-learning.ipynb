{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0201af70",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network\n",
    "Predict daily high and low temperatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253e2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# workaround for MacOS/jupyter notebook bug w/ tensorflow\n",
    "# https://www.programmersought.com/article/69923598438/\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6056b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4471)\n",
    "# https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "# https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "weather_pd = pd.read_csv('../data/weather.csv', index_col = 0)\n",
    "weather_pd = weather_pd.drop(['DAY', 'STP', 'GUST'], axis=1)\n",
    "weather_np = weather_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd4e991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>SLP</th>\n",
       "      <th>VISIB</th>\n",
       "      <th>WDSP</th>\n",
       "      <th>MXSPD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>1023.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>66.9</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1024.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1014.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1019.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>57.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  SEASON  TEMP  DEWP     SLP  VISIB  WDSP  MXSPD   MAX   MIN  \\\n",
       "0  2000      1       0  47.6  38.1  1023.7    8.3   3.0   10.1  66.9  33.1   \n",
       "1  2000      1       0  55.3  46.3  1024.2    9.5   4.8   14.0  70.0  33.1   \n",
       "2  2000      1       0  62.6  55.4  1021.3    8.4   8.5   14.0  73.9  43.0   \n",
       "3  2000      1       0  65.2  58.6  1014.4    9.5  15.3   28.0  73.9  55.0   \n",
       "4  2000      1       0  45.7  30.9  1019.8    9.8   6.4   11.1  57.9  37.0   \n",
       "\n",
       "   PRCP  SNDP  \n",
       "0  0.00   0.0  \n",
       "1  0.00   0.0  \n",
       "2  0.00   0.0  \n",
       "3  0.00   0.0  \n",
       "4  0.34   0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9941bf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR        int64\n",
       "MONTH       int64\n",
       "SEASON      int64\n",
       "TEMP      float64\n",
       "DEWP      float64\n",
       "SLP       float64\n",
       "VISIB     float64\n",
       "WDSP      float64\n",
       "MXSPD     float64\n",
       "MAX       float64\n",
       "MIN       float64\n",
       "PRCP      float64\n",
       "SNDP      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ee5a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7771,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([70., 74., 74., ..., 87., 85., 58.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next day's weather\n",
    "target = weather_pd[['MAX']].iloc[1:, :] # 'MIN'\n",
    "target = np.round(target.values.reshape(-1))\n",
    "print(target.shape)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c098cdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>SLP</th>\n",
       "      <th>VISIB</th>\n",
       "      <th>WDSP</th>\n",
       "      <th>MXSPD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>1023.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>66.9</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1024.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1014.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1019.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>57.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  SEASON  TEMP  DEWP     SLP  VISIB  WDSP  MXSPD   MAX   MIN  \\\n",
       "0  2000      1       0  47.6  38.1  1023.7    8.3   3.0   10.1  66.9  33.1   \n",
       "1  2000      1       0  55.3  46.3  1024.2    9.5   4.8   14.0  70.0  33.1   \n",
       "2  2000      1       0  62.6  55.4  1021.3    8.4   8.5   14.0  73.9  43.0   \n",
       "3  2000      1       0  65.2  58.6  1014.4    9.5  15.3   28.0  73.9  55.0   \n",
       "4  2000      1       0  45.7  30.9  1019.8    9.8   6.4   11.1  57.9  37.0   \n",
       "\n",
       "   PRCP  SNDP  \n",
       "0  0.00   0.0  \n",
       "1  0.00   0.0  \n",
       "2  0.00   0.0  \n",
       "3  0.00   0.0  \n",
       "4  0.34   0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# today's weather\n",
    "feature = weather_pd.iloc[:-1, :] # don't have next day on last day\n",
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69793159",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = tf.data.Dataset.from_tensor_slices((feature.values, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66574d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 4.7600e+01 3.8100e+01 1.0237e+03\n",
      " 8.3000e+00 3.0000e+00 1.0100e+01 6.6900e+01 3.3100e+01 0.0000e+00\n",
      " 0.0000e+00], Target: 70.0\n",
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 5.5300e+01 4.6300e+01 1.0242e+03\n",
      " 9.5000e+00 4.8000e+00 1.4000e+01 7.0000e+01 3.3100e+01 0.0000e+00\n",
      " 0.0000e+00], Target: 74.0\n",
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 6.2600e+01 5.5400e+01 1.0213e+03\n",
      " 8.4000e+00 8.5000e+00 1.4000e+01 7.3900e+01 4.3000e+01 0.0000e+00\n",
      " 0.0000e+00], Target: 74.0\n",
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 6.5200e+01 5.8600e+01 1.0144e+03\n",
      " 9.5000e+00 1.5300e+01 2.8000e+01 7.3900e+01 5.5000e+01 0.0000e+00\n",
      " 0.0000e+00], Target: 58.0\n",
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 4.5700e+01 3.0900e+01 1.0198e+03\n",
      " 9.8000e+00 6.4000e+00 1.1100e+01 5.7900e+01 3.7000e+01 3.4000e-01\n",
      " 0.0000e+00], Target: 51.0\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in weather.take(5):\n",
    "    print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a9193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((4, 13), (4,)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batches of days - ues previous 3 days to predict 4th day?\n",
    "days_in_batches = 4 # change to 3 later\n",
    "batches = weather.batch(days_in_batches, drop_remainder=True)\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "031c27eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 4.7600e+01 3.8100e+01 1.0237e+03\n",
      "  8.3000e+00 3.0000e+00 1.0100e+01 6.6900e+01 3.3100e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 5.5300e+01 4.6300e+01 1.0242e+03\n",
      "  9.5000e+00 4.8000e+00 1.4000e+01 7.0000e+01 3.3100e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 6.2600e+01 5.5400e+01 1.0213e+03\n",
      "  8.4000e+00 8.5000e+00 1.4000e+01 7.3900e+01 4.3000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 6.5200e+01 5.8600e+01 1.0144e+03\n",
      "  9.5000e+00 1.5300e+01 2.8000e+01 7.3900e+01 5.5000e+01 0.0000e+00\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([70. 74. 74. 58.], shape=(4,), dtype=float64)\n",
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 4.5700e+01 3.0900e+01 1.0198e+03\n",
      "  9.8000e+00 6.4000e+00 1.1100e+01 5.7900e+01 3.7000e+01 3.4000e-01\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.6100e+01 2.7200e+01 1.0324e+03\n",
      "  9.9000e+00 1.8000e+00 7.0000e+00 5.1100e+01 2.5000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 4.7400e+01 3.5000e+01 1.0275e+03\n",
      "  9.2000e+00 3.2000e+00 1.0100e+01 5.7900e+01 2.5000e+01 4.0000e-02\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.8600e+01 2.5200e+01 1.0283e+03\n",
      "  9.9000e+00 1.7000e+00 5.1000e+00 5.7900e+01 2.6100e+01 8.0000e-02\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([51. 58. 58. 54.], shape=(4,), dtype=float64)\n",
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 4.4300e+01 3.9000e+01 1.0214e+03\n",
      "  6.9000e+00 3.2000e+00 6.0000e+00 5.4000e+01 2.6100e+01 4.0000e-02\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 5.6900e+01 5.4200e+01 1.0098e+03\n",
      "  4.7000e+00 9.4000e+00 2.2000e+01 6.6000e+01 4.1000e+01 5.9000e-01\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 5.4900e+01 3.3600e+01 1.0113e+03\n",
      "  9.9000e+00 1.1400e+01 2.4100e+01 7.0000e+01 4.3000e+01 9.0000e-01\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 4.8200e+01 1.9800e+01 1.0219e+03\n",
      "  9.9000e+00 3.4000e+00 1.1100e+01 6.2100e+01 3.0200e+01 0.0000e+00\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([66. 70. 62. 70.], shape=(4,), dtype=float64)\n",
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 5.4700e+01 3.6800e+01 1.0162e+03\n",
      "  1.0000e+01 9.8000e+00 1.9000e+01 7.0000e+01 4.6900e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.5900e+01 1.0200e+01 1.0320e+03\n",
      "  9.9000e+00 8.4000e+00 1.9000e+01 5.2000e+01 2.8000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.0200e+01 8.8000e+00 1.0390e+03\n",
      "  9.9000e+00 3.0000e+00 8.9000e+00 4.4100e+01 1.9000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 4.5600e+01 2.1200e+01 1.0274e+03\n",
      "  9.8000e+00 1.1000e+01 1.8100e+01 6.3000e+01 3.6000e+01 0.0000e+00\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([52. 44. 63. 63.], shape=(4,), dtype=float64)\n",
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 4.3000e+01 1.5500e+01 1.0270e+03\n",
      "  9.9000e+00 6.8000e+00 1.5000e+01 6.3000e+01 3.2000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 2.6600e+01 1.4000e+01 1.0235e+03\n",
      "  5.1000e+00 3.6000e+00 8.0000e+00 3.3100e+01 2.1200e+01 9.0000e-02\n",
      "  3.1000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.0500e+01 2.7200e+01 1.0168e+03\n",
      "  5.4000e+00 2.7000e+00 8.0000e+00 3.9900e+01 2.1900e+01 1.0000e-01\n",
      "  2.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.5700e+01 2.8400e+01 1.0061e+03\n",
      "  6.3000e+00 7.1000e+00 1.5000e+01 4.5000e+01 2.4100e+01 2.6000e-01\n",
      "  2.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([33. 40. 45. 45.], shape=(4,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# see batches of days\n",
    "for input_ex, target_ex in batches.take(5):\n",
    "    print('Input data: ', input_ex)\n",
    "    print('Target data: ', target_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05720a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: [2.000e+03 1.000e+00 0.000e+00 4.300e+01 1.550e+01 1.027e+03 9.900e+00\n",
      " 6.800e+00 1.500e+01 6.300e+01 3.200e+01 0.000e+00 0.000e+00]\n",
      "  expected output: 33.0\n",
      "Step    1\n",
      "  input: [2.0000e+03 1.0000e+00 0.0000e+00 2.6600e+01 1.4000e+01 1.0235e+03\n",
      " 5.1000e+00 3.6000e+00 8.0000e+00 3.3100e+01 2.1200e+01 9.0000e-02\n",
      " 3.1000e+00]\n",
      "  expected output: 40.0\n",
      "Step    2\n",
      "  input: [2.0000e+03 1.0000e+00 0.0000e+00 3.0500e+01 2.7200e+01 1.0168e+03\n",
      " 5.4000e+00 2.7000e+00 8.0000e+00 3.9900e+01 2.1900e+01 1.0000e-01\n",
      " 2.0000e+00]\n",
      "  expected output: 45.0\n",
      "Step    3\n",
      "  input: [2.0000e+03 1.0000e+00 0.0000e+00 3.5700e+01 2.8400e+01 1.0061e+03\n",
      " 6.3000e+00 7.1000e+00 1.5000e+01 4.5000e+01 2.4100e+01 2.6000e-01\n",
      " 2.0000e+00]\n",
      "  expected output: 45.0\n"
     ]
    }
   ],
   "source": [
    "# see expected output for each input\n",
    "for i, (input_idx, target_idx) in enumerate(zip(input_ex[:5], target_ex[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {}\".format(input_idx))\n",
    "    print(\"  expected output: {}\".format(target_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98fce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 4, 13), (64, 4)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make batches of the 4-day batches\n",
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "batch_weather = batches.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "batch_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ea51e",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "817a040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many possible outputs\n",
    "num_output_vals = int(max(target)) + 5 # maximum temperature observed (105) plus some margin\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66fb0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(rnn_units, num_output_vals, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform',\n",
    "                            batch_input_shape = (64, 4, 13)),\n",
    "        tf.keras.layers.Dense(num_output_vals)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56867f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(rnn_units, num_output_vals, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54f50387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set floats to float64 to avoid warning message\n",
    "# tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368aca46",
   "metadata": {},
   "source": [
    "## Try the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a8435cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(64, 4, 110) # (batch_size, days_in_batches, num_output_vals)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in batch_weather.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, days_in_batches, num_output_vals)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "896c0808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_example_batch.shape # 512 total # need another dim??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8718484d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 4, 13])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example_batch.shape # 64*52=3328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5789fcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 4, 110])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ce6cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (64, 4, 16)               1488      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, 4, 110)              1870      \n",
      "=================================================================\n",
      "Total params: 3,358\n",
      "Trainable params: 3,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de2de19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([84, 12, 38, 35])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example predictions, all terrible bc model not trained\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf7cc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " tf.Tensor(\n",
      "[[2.0050e+03 1.1000e+01 3.0000e+00 3.7300e+01 1.9900e+01 1.0283e+03\n",
      "  1.0000e+01 1.5000e+00 6.0000e+00 5.5900e+01 2.3000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0050e+03 1.1000e+01 3.0000e+00 4.5000e+01 3.1800e+01 1.0264e+03\n",
      "  1.0000e+01 1.3000e+00 5.1000e+00 5.7900e+01 2.3000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0050e+03 1.1000e+01 3.0000e+00 5.2900e+01 5.0300e+01 1.0136e+03\n",
      "  3.1000e+00 4.7000e+00 1.5000e+01 5.7900e+01 3.5100e+01 7.7000e-01\n",
      "  0.0000e+00]\n",
      " [2.0050e+03 1.1000e+01 3.0000e+00 4.8300e+01 4.0300e+01 9.9580e+02\n",
      "  6.2000e+00 7.9000e+00 1.5000e+01 5.4000e+01 4.2800e+01 1.2700e+00\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "\n",
      "Next Day Predictions: \n",
      " [84 12 38 35]\n"
     ]
    }
   ],
   "source": [
    "# show input and output\n",
    "print(\"Input: \\n\", input_example_batch[0])\n",
    "print()\n",
    "print(\"Next Day Predictions: \\n\", sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39d0327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 4, 110)  # (batch_size, days_in_batches, num_output_vals)\n",
      "Mean loss:         4.750641\n"
     ]
    }
   ],
   "source": [
    "# do we need logits for loss function? from_logits=True\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, days_in_batches, num_output_vals)\")\n",
    "print(\"Mean loss:        \", mean_loss)\n",
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24ff8680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.65839"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exponential of the mean loss ~= num outputs\n",
    "tf.exp(mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b441baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8d1bd",
   "metadata": {},
   "source": [
    "## Configure Checkpoints\n",
    "save checkpoints during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80e9e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training-checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd30e5",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51c71daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8803f8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "30/30 [==============================] - 3s 89ms/step - loss: 4.6585\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.4770\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.3558\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.2747\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.2226\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1889\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1637\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1436\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1336\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1231\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1171\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1101\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1065\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1005\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0991\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 4.0973\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 4.0949\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 4.0904\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 4.0914\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 4.0908\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0883\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0882\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0857\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0829\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0857\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0780\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0759\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0794\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 4.0790\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.0814\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(batch_weather, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6dd0f6",
   "metadata": {},
   "source": [
    "## Restore Latest Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f3f8fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (64, 4, 16)               1488      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, 4, 110)              1870      \n",
      "=================================================================\n",
      "Total params: 3,358\n",
      "Trainable params: 3,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "model = build_model(rnn_units, num_output_vals, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58de56ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6798, shape=(4, 13), dtype=float64, numpy=\n",
       "array([[2.0050e+03, 1.1000e+01, 3.0000e+00, 3.7300e+01, 1.9900e+01,\n",
       "        1.0283e+03, 1.0000e+01, 1.5000e+00, 6.0000e+00, 5.5900e+01,\n",
       "        2.3000e+01, 0.0000e+00, 0.0000e+00],\n",
       "       [2.0050e+03, 1.1000e+01, 3.0000e+00, 4.5000e+01, 3.1800e+01,\n",
       "        1.0264e+03, 1.0000e+01, 1.3000e+00, 5.1000e+00, 5.7900e+01,\n",
       "        2.3000e+01, 0.0000e+00, 0.0000e+00],\n",
       "       [2.0050e+03, 1.1000e+01, 3.0000e+00, 5.2900e+01, 5.0300e+01,\n",
       "        1.0136e+03, 3.1000e+00, 4.7000e+00, 1.5000e+01, 5.7900e+01,\n",
       "        3.5100e+01, 7.7000e-01, 0.0000e+00],\n",
       "       [2.0050e+03, 1.1000e+01, 3.0000e+00, 4.8300e+01, 4.0300e+01,\n",
       "        9.9580e+02, 6.2000e+00, 7.9000e+00, 1.5000e+01, 5.4000e+01,\n",
       "        4.2800e+01, 1.2700e+00, 0.0000e+00]])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weather_np[0, :]\n",
    "print(input_example_batch.shape)\n",
    "input_example_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7cb3440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6558, shape=(64, 4, 110), dtype=float32, numpy=\n",
       "array([[[-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261]],\n",
       "\n",
       "       [[-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261]],\n",
       "\n",
       "       [[-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261]],\n",
       "\n",
       "       [[-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261]],\n",
       "\n",
       "       [[-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261],\n",
       "        [-3.09098  , -3.4213858, -3.1027224, ..., -2.6409898,\n",
       "         -2.7408054, -3.1172261]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset_states()\n",
    "model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da5e9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weather(model, start_weather):\n",
    "    # Evaluation step (generating weather using the learned model)\n",
    "\n",
    "    # Number of days to generate\n",
    "    num_generate = 20\n",
    "\n",
    "    # Empty string to store our results\n",
    "    days_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable results.\n",
    "    # Higher temperatures results in more surprising results.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(start_weather)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the temperature returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted temp as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        days_generated.append([predicted_id])\n",
    "\n",
    "    return (start_weather, days_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a1aac36",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Can not squeeze dim[0], expected a dimension of 1, got 64 [Op:Squeeze]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7d2092cfb706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_weather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_weather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_example_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-eeb3fd7cc1f6>\u001b[0m in \u001b[0;36mgenerate_weather\u001b[0;34m(model, start_weather)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_weather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# remove the batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# using a categorical distribution to predict the temperature returned by the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml-tensor/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml-tensor/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36msqueeze_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   3699\u001b[0m   \"\"\"\n\u001b[1;32m   3700\u001b[0m   \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3701\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml-tensor/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml-tensor/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml-tensor/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(input, axis, name, squeeze_dims)\u001b[0m\n\u001b[1;32m   3647\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3648\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3649\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml-tensor/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m  10059\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10060\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10061\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10062\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10063\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml-tensor/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[0], expected a dimension of 1, got 64 [Op:Squeeze]"
     ]
    }
   ],
   "source": [
    "print(generate_weather(model, start_weather=input_example_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759a8e8",
   "metadata": {},
   "source": [
    "#### Resources Consulted\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
