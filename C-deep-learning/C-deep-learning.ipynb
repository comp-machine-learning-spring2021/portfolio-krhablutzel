{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0201af70",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network\n",
    "Predict daily high and low temperatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "253e2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# workaround for MacOS/jupyter notebook bug w/ tensorflow\n",
    "# https://www.programmersought.com/article/69923598438/\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6056b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4471)\n",
    "# https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "# https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "weather_pd = pd.read_csv('../data/weather.csv', index_col = 0)\n",
    "weather_pd = weather_pd.drop(['DAY', 'STP', 'GUST'], axis=1)\n",
    "weather_np = weather_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bfd4e991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>SLP</th>\n",
       "      <th>VISIB</th>\n",
       "      <th>WDSP</th>\n",
       "      <th>MXSPD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>1023.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>66.9</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1024.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1014.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1019.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>57.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  SEASON  TEMP  DEWP     SLP  VISIB  WDSP  MXSPD   MAX   MIN  \\\n",
       "0  2000      1       0  47.6  38.1  1023.7    8.3   3.0   10.1  66.9  33.1   \n",
       "1  2000      1       0  55.3  46.3  1024.2    9.5   4.8   14.0  70.0  33.1   \n",
       "2  2000      1       0  62.6  55.4  1021.3    8.4   8.5   14.0  73.9  43.0   \n",
       "3  2000      1       0  65.2  58.6  1014.4    9.5  15.3   28.0  73.9  55.0   \n",
       "4  2000      1       0  45.7  30.9  1019.8    9.8   6.4   11.1  57.9  37.0   \n",
       "\n",
       "   PRCP  SNDP  \n",
       "0  0.00   0.0  \n",
       "1  0.00   0.0  \n",
       "2  0.00   0.0  \n",
       "3  0.00   0.0  \n",
       "4  0.34   0.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9941bf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR        int64\n",
       "MONTH       int64\n",
       "SEASON      int64\n",
       "TEMP      float64\n",
       "DEWP      float64\n",
       "SLP       float64\n",
       "VISIB     float64\n",
       "WDSP      float64\n",
       "MXSPD     float64\n",
       "MAX       float64\n",
       "MIN       float64\n",
       "PRCP      float64\n",
       "SNDP      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8ee5a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7771,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([70., 74., 74., ..., 87., 85., 58.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next day's weather\n",
    "target = weather_pd[['MAX']].iloc[1:, :] # 'MIN'\n",
    "target = np.round(target.values.reshape(-1))\n",
    "print(target.shape)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c098cdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>SLP</th>\n",
       "      <th>VISIB</th>\n",
       "      <th>WDSP</th>\n",
       "      <th>MXSPD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>1023.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>66.9</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1024.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1014.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1019.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>57.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  SEASON  TEMP  DEWP     SLP  VISIB  WDSP  MXSPD   MAX   MIN  \\\n",
       "0  2000      1       0  47.6  38.1  1023.7    8.3   3.0   10.1  66.9  33.1   \n",
       "1  2000      1       0  55.3  46.3  1024.2    9.5   4.8   14.0  70.0  33.1   \n",
       "2  2000      1       0  62.6  55.4  1021.3    8.4   8.5   14.0  73.9  43.0   \n",
       "3  2000      1       0  65.2  58.6  1014.4    9.5  15.3   28.0  73.9  55.0   \n",
       "4  2000      1       0  45.7  30.9  1019.8    9.8   6.4   11.1  57.9  37.0   \n",
       "\n",
       "   PRCP  SNDP  \n",
       "0  0.00   0.0  \n",
       "1  0.00   0.0  \n",
       "2  0.00   0.0  \n",
       "3  0.00   0.0  \n",
       "4  0.34   0.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# today's weather\n",
    "feature = weather_pd.iloc[:-1, :] # don't have next day on last day\n",
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69793159",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = tf.data.Dataset.from_tensor_slices((feature.values, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "66574d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 4.7600e+01 3.8100e+01 1.0237e+03\n",
      " 8.3000e+00 3.0000e+00 1.0100e+01 6.6900e+01 3.3100e+01 0.0000e+00\n",
      " 0.0000e+00], Target: 70.0\n",
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 5.5300e+01 4.6300e+01 1.0242e+03\n",
      " 9.5000e+00 4.8000e+00 1.4000e+01 7.0000e+01 3.3100e+01 0.0000e+00\n",
      " 0.0000e+00], Target: 74.0\n",
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 6.2600e+01 5.5400e+01 1.0213e+03\n",
      " 8.4000e+00 8.5000e+00 1.4000e+01 7.3900e+01 4.3000e+01 0.0000e+00\n",
      " 0.0000e+00], Target: 74.0\n",
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 6.5200e+01 5.8600e+01 1.0144e+03\n",
      " 9.5000e+00 1.5300e+01 2.8000e+01 7.3900e+01 5.5000e+01 0.0000e+00\n",
      " 0.0000e+00], Target: 58.0\n",
      "Features: [2.0000e+03 1.0000e+00 0.0000e+00 4.5700e+01 3.0900e+01 1.0198e+03\n",
      " 9.8000e+00 6.4000e+00 1.1100e+01 5.7900e+01 3.7000e+01 3.4000e-01\n",
      " 0.0000e+00], Target: 51.0\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in weather.take(5):\n",
    "    print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c3a9193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((4, 13), (4,)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batches of days - ues previous 3 days to predict 4th day?\n",
    "days_in_batches = 4 # change to 3 later\n",
    "batches = weather.batch(days_in_batches, drop_remainder=True)\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "031c27eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 4.7600e+01 3.8100e+01 1.0237e+03\n",
      "  8.3000e+00 3.0000e+00 1.0100e+01 6.6900e+01 3.3100e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 5.5300e+01 4.6300e+01 1.0242e+03\n",
      "  9.5000e+00 4.8000e+00 1.4000e+01 7.0000e+01 3.3100e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 6.2600e+01 5.5400e+01 1.0213e+03\n",
      "  8.4000e+00 8.5000e+00 1.4000e+01 7.3900e+01 4.3000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 6.5200e+01 5.8600e+01 1.0144e+03\n",
      "  9.5000e+00 1.5300e+01 2.8000e+01 7.3900e+01 5.5000e+01 0.0000e+00\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([70. 74. 74. 58.], shape=(4,), dtype=float64)\n",
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 4.5700e+01 3.0900e+01 1.0198e+03\n",
      "  9.8000e+00 6.4000e+00 1.1100e+01 5.7900e+01 3.7000e+01 3.4000e-01\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.6100e+01 2.7200e+01 1.0324e+03\n",
      "  9.9000e+00 1.8000e+00 7.0000e+00 5.1100e+01 2.5000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 4.7400e+01 3.5000e+01 1.0275e+03\n",
      "  9.2000e+00 3.2000e+00 1.0100e+01 5.7900e+01 2.5000e+01 4.0000e-02\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.8600e+01 2.5200e+01 1.0283e+03\n",
      "  9.9000e+00 1.7000e+00 5.1000e+00 5.7900e+01 2.6100e+01 8.0000e-02\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([51. 58. 58. 54.], shape=(4,), dtype=float64)\n",
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 4.4300e+01 3.9000e+01 1.0214e+03\n",
      "  6.9000e+00 3.2000e+00 6.0000e+00 5.4000e+01 2.6100e+01 4.0000e-02\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 5.6900e+01 5.4200e+01 1.0098e+03\n",
      "  4.7000e+00 9.4000e+00 2.2000e+01 6.6000e+01 4.1000e+01 5.9000e-01\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 5.4900e+01 3.3600e+01 1.0113e+03\n",
      "  9.9000e+00 1.1400e+01 2.4100e+01 7.0000e+01 4.3000e+01 9.0000e-01\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 4.8200e+01 1.9800e+01 1.0219e+03\n",
      "  9.9000e+00 3.4000e+00 1.1100e+01 6.2100e+01 3.0200e+01 0.0000e+00\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([66. 70. 62. 70.], shape=(4,), dtype=float64)\n",
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 5.4700e+01 3.6800e+01 1.0162e+03\n",
      "  1.0000e+01 9.8000e+00 1.9000e+01 7.0000e+01 4.6900e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.5900e+01 1.0200e+01 1.0320e+03\n",
      "  9.9000e+00 8.4000e+00 1.9000e+01 5.2000e+01 2.8000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.0200e+01 8.8000e+00 1.0390e+03\n",
      "  9.9000e+00 3.0000e+00 8.9000e+00 4.4100e+01 1.9000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 4.5600e+01 2.1200e+01 1.0274e+03\n",
      "  9.8000e+00 1.1000e+01 1.8100e+01 6.3000e+01 3.6000e+01 0.0000e+00\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([52. 44. 63. 63.], shape=(4,), dtype=float64)\n",
      "Input data:  tf.Tensor(\n",
      "[[2.0000e+03 1.0000e+00 0.0000e+00 4.3000e+01 1.5500e+01 1.0270e+03\n",
      "  9.9000e+00 6.8000e+00 1.5000e+01 6.3000e+01 3.2000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 2.6600e+01 1.4000e+01 1.0235e+03\n",
      "  5.1000e+00 3.6000e+00 8.0000e+00 3.3100e+01 2.1200e+01 9.0000e-02\n",
      "  3.1000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.0500e+01 2.7200e+01 1.0168e+03\n",
      "  5.4000e+00 2.7000e+00 8.0000e+00 3.9900e+01 2.1900e+01 1.0000e-01\n",
      "  2.0000e+00]\n",
      " [2.0000e+03 1.0000e+00 0.0000e+00 3.5700e+01 2.8400e+01 1.0061e+03\n",
      "  6.3000e+00 7.1000e+00 1.5000e+01 4.5000e+01 2.4100e+01 2.6000e-01\n",
      "  2.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "Target data:  tf.Tensor([33. 40. 45. 45.], shape=(4,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# see batches of days\n",
    "for input_ex, target_ex in batches.take(5):\n",
    "    print('Input data: ', input_ex)\n",
    "    print('Target data: ', target_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f05720a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: [2.000e+03 1.000e+00 0.000e+00 4.300e+01 1.550e+01 1.027e+03 9.900e+00\n",
      " 6.800e+00 1.500e+01 6.300e+01 3.200e+01 0.000e+00 0.000e+00]\n",
      "  expected output: 33.0\n",
      "Step    1\n",
      "  input: [2.0000e+03 1.0000e+00 0.0000e+00 2.6600e+01 1.4000e+01 1.0235e+03\n",
      " 5.1000e+00 3.6000e+00 8.0000e+00 3.3100e+01 2.1200e+01 9.0000e-02\n",
      " 3.1000e+00]\n",
      "  expected output: 40.0\n",
      "Step    2\n",
      "  input: [2.0000e+03 1.0000e+00 0.0000e+00 3.0500e+01 2.7200e+01 1.0168e+03\n",
      " 5.4000e+00 2.7000e+00 8.0000e+00 3.9900e+01 2.1900e+01 1.0000e-01\n",
      " 2.0000e+00]\n",
      "  expected output: 45.0\n",
      "Step    3\n",
      "  input: [2.0000e+03 1.0000e+00 0.0000e+00 3.5700e+01 2.8400e+01 1.0061e+03\n",
      " 6.3000e+00 7.1000e+00 1.5000e+01 4.5000e+01 2.4100e+01 2.6000e-01\n",
      " 2.0000e+00]\n",
      "  expected output: 45.0\n"
     ]
    }
   ],
   "source": [
    "# see expected output for each input\n",
    "for i, (input_idx, target_idx) in enumerate(zip(input_ex[:5], target_ex[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {}\".format(input_idx))\n",
    "    print(\"  expected output: {}\".format(target_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f98fce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((16, 4, 13), (16, 4)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make batches of the 4-day batches\n",
    "# Batch size\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "batch_weather = batches.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "batch_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ea51e",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "817a040a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many possible outputs\n",
    "num_output_vals = int(max(target)) + 5 # maximum temperature observed (105) plus some margin\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 16\n",
    "\n",
    "# conveniently, min min temperature is 1\n",
    "min(target_old[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "66fb0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(rnn_units, num_output_vals, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32, batch_input_shape = (batch_size, 4, 13)),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(num_output_vals)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "56867f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(rnn_units, num_output_vals, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "54f50387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set floats to float64 to avoid warning message\n",
    "# tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368aca46",
   "metadata": {},
   "source": [
    "## Try the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1a8435cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(16, 4, 110) # (batch_size, days_in_batches, num_output_vals)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in batch_weather.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, days_in_batches, num_output_vals)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "896c0808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 4])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_example_batch.shape # 512 total # need another dim??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8718484d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 4, 13])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example_batch.shape # 64*52=3328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5789fcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 4, 110])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3ce6cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (16, 4, 32)               448       \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (16, 4, 16)               2400      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (16, 4, 110)              1870      \n",
      "=================================================================\n",
      "Total params: 4,718\n",
      "Trainable params: 4,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "de2de19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 64, 68, 90])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example predictions, all terrible bc model not trained\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fdf7cc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " tf.Tensor(\n",
      "[[2.0050e+03 9.0000e+00 2.0000e+00 7.9100e+01 6.7900e+01 1.0150e+03\n",
      "  7.1000e+00 4.5000e+00 8.0000e+00 9.3900e+01 7.0000e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0050e+03 9.0000e+00 2.0000e+00 7.8200e+01 6.6700e+01 1.0146e+03\n",
      "  7.8000e+00 3.1000e+00 8.0000e+00 9.5000e+01 6.4900e+01 1.0000e-02\n",
      "  0.0000e+00]\n",
      " [2.0050e+03 9.0000e+00 2.0000e+00 7.9100e+01 6.5100e+01 1.0158e+03\n",
      "  8.7000e+00 3.3000e+00 8.0000e+00 9.5000e+01 6.4900e+01 0.0000e+00\n",
      "  0.0000e+00]\n",
      " [2.0050e+03 9.0000e+00 2.0000e+00 7.8200e+01 6.7900e+01 1.0207e+03\n",
      "  5.3000e+00 5.0000e+00 1.3000e+01 9.3900e+01 6.6900e+01 0.0000e+00\n",
      "  0.0000e+00]], shape=(4, 13), dtype=float64)\n",
      "\n",
      "Next Day Predictions: \n",
      " [ 3 64 68 90]\n"
     ]
    }
   ],
   "source": [
    "# show input and output\n",
    "print(\"Input: \\n\", input_example_batch[0])\n",
    "print()\n",
    "print(\"Next Day Predictions: \\n\", sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "39d0327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (16, 4, 110)  # (batch_size, days_in_batches, num_output_vals)\n",
      "Mean loss:         4.7404647\n"
     ]
    }
   ],
   "source": [
    "# do we need logits for loss function? from_logits=True\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, days_in_batches, num_output_vals)\")\n",
    "print(\"Mean loss:        \", mean_loss)\n",
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "24ff8680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.48739"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exponential of the mean loss ~= num outputs\n",
    "tf.exp(mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5b441baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8d1bd",
   "metadata": {},
   "source": [
    "## Configure Checkpoints\n",
    "save checkpoints during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "80e9e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training-checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd30e5",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "51c71daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8803f8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 4.4985\n",
      "Epoch 2/30\n",
      "121/121 [==============================] - 1s 9ms/step - loss: 4.2491\n",
      "Epoch 3/30\n",
      "121/121 [==============================] - 1s 9ms/step - loss: 4.1588\n",
      "Epoch 4/30\n",
      "121/121 [==============================] - 1s 9ms/step - loss: 4.1241\n",
      "Epoch 5/30\n",
      "121/121 [==============================] - 1s 9ms/step - loss: 4.1087\n",
      "Epoch 6/30\n",
      "121/121 [==============================] - 1s 9ms/step - loss: 4.0975\n",
      "Epoch 7/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0934\n",
      "Epoch 8/30\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 4.0871\n",
      "Epoch 9/30\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 4.0833\n",
      "Epoch 10/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0827\n",
      "Epoch 11/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0822\n",
      "Epoch 12/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0780\n",
      "Epoch 13/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0790\n",
      "Epoch 14/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0761\n",
      "Epoch 15/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0748\n",
      "Epoch 16/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0755\n",
      "Epoch 17/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0778\n",
      "Epoch 18/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0768\n",
      "Epoch 19/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0744\n",
      "Epoch 20/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0764\n",
      "Epoch 21/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0747\n",
      "Epoch 22/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0756\n",
      "Epoch 23/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0742\n",
      "Epoch 24/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0731\n",
      "Epoch 25/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0742\n",
      "Epoch 26/30\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 4.0721\n",
      "Epoch 27/30\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 4.0737\n",
      "Epoch 28/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0729\n",
      "Epoch 29/30\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 4.0731\n",
      "Epoch 30/30\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 4.0745\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(batch_weather, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6dd0f6",
   "metadata": {},
   "source": [
    "## Restore Latest Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7f3f8fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (1, 4, 32)                448       \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (1, 4, 16)                2400      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (1, 4, 110)               1870      \n",
      "=================================================================\n",
      "Total params: 4,718\n",
      "Trainable params: 4,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "model = build_model(rnn_units, num_output_vals, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "58de56ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=42049, shape=(1, 4, 13), dtype=float64, numpy=\n",
       "array([[[2.0050e+03, 9.0000e+00, 2.0000e+00, 7.9100e+01, 6.7900e+01,\n",
       "         1.0150e+03, 7.1000e+00, 4.5000e+00, 8.0000e+00, 9.3900e+01,\n",
       "         7.0000e+01, 0.0000e+00, 0.0000e+00],\n",
       "        [2.0050e+03, 9.0000e+00, 2.0000e+00, 7.8200e+01, 6.6700e+01,\n",
       "         1.0146e+03, 7.8000e+00, 3.1000e+00, 8.0000e+00, 9.5000e+01,\n",
       "         6.4900e+01, 1.0000e-02, 0.0000e+00],\n",
       "        [2.0050e+03, 9.0000e+00, 2.0000e+00, 7.9100e+01, 6.5100e+01,\n",
       "         1.0158e+03, 8.7000e+00, 3.3000e+00, 8.0000e+00, 9.5000e+01,\n",
       "         6.4900e+01, 0.0000e+00, 0.0000e+00],\n",
       "        [2.0050e+03, 9.0000e+00, 2.0000e+00, 7.8200e+01, 6.7900e+01,\n",
       "         1.0207e+03, 5.3000e+00, 5.0000e+00, 1.3000e+01, 9.3900e+01,\n",
       "         6.6900e+01, 0.0000e+00, 0.0000e+00]]])>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weather_np[0, :]\n",
    "print(input_example_batch.shape)\n",
    "input_example_batch[0:1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d7cb3440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 110)\n",
      "93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53861, shape=(1, 1), dtype=int32, numpy=array([[93]], dtype=int32)>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset_states()\n",
    "test = input_example_batch[0:1, :, :]\n",
    "predictions = model(test)\n",
    "predictions = tf.squeeze(predictions, 0)\n",
    "predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "test = tf.expand_dims([predicted_id], 0)\n",
    "print(predictions.shape)\n",
    "print(predicted_id)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "da5e9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weather(model, start_weather):\n",
    "    # Evaluation step (generating weather using the learned model)\n",
    "\n",
    "    # Number of days to generate\n",
    "    # only generate 1 day because we don't know the rest of the weather for the day to use as input\n",
    "    num_generate = 1\n",
    "\n",
    "    # Empty string to store our results\n",
    "    days_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable results.\n",
    "    # Higher temperatures results in more surprising results.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(start_weather)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the temperature returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        days_generated.append(predicted_id)\n",
    "\n",
    "    return (start_weather, days_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9a1aac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=53865, shape=(1, 4, 13), dtype=float64, numpy=\n",
      "array([[[2.0050e+03, 9.0000e+00, 2.0000e+00, 7.9100e+01, 6.7900e+01,\n",
      "         1.0150e+03, 7.1000e+00, 4.5000e+00, 8.0000e+00, 9.3900e+01,\n",
      "         7.0000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0050e+03, 9.0000e+00, 2.0000e+00, 7.8200e+01, 6.6700e+01,\n",
      "         1.0146e+03, 7.8000e+00, 3.1000e+00, 8.0000e+00, 9.5000e+01,\n",
      "         6.4900e+01, 1.0000e-02, 0.0000e+00],\n",
      "        [2.0050e+03, 9.0000e+00, 2.0000e+00, 7.9100e+01, 6.5100e+01,\n",
      "         1.0158e+03, 8.7000e+00, 3.3000e+00, 8.0000e+00, 9.5000e+01,\n",
      "         6.4900e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0050e+03, 9.0000e+00, 2.0000e+00, 7.8200e+01, 6.7900e+01,\n",
      "         1.0207e+03, 5.3000e+00, 5.0000e+00, 1.3000e+01, 9.3900e+01,\n",
      "         6.6900e+01, 0.0000e+00, 0.0000e+00]]])>, [61])\n"
     ]
    }
   ],
   "source": [
    "print(generate_weather(model, start_weather=input_example_batch[0:1, :, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d561e",
   "metadata": {},
   "source": [
    "## Predict a few days of weather\n",
    "- for each set of 4 days, see if next day is right\n",
    "- given rest of vars and model's high temp, what are the temp predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a51cf",
   "metadata": {},
   "source": [
    "## Just predict high temp from high temp\n",
    "so we can go 4 days out in predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759a8e8",
   "metadata": {},
   "source": [
    "#### Resources Consulted\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
