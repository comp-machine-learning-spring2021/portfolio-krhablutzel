{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0201af70",
   "metadata": {},
   "source": [
    "# Will it Rain Tomorrow?\n",
    "### Deep Learning with Neural Networks and RNNs\n",
    "\n",
    "For the third component of this portfolio, I wanted to explore a less abstract question about North Carolina's weather than the previous two projects. Unless someone is a time traveler, emerging from a coma, or visiting from the Southern Hemisphere, they probably have a reasonable sense of approximately what season it is. In this project, I address a much more practical and common weather question: *Will it rain tomorrow?*\n",
    "\n",
    "To answer that question, I build two deep learning models: a standard neural network to predict whether it will rain tomorrow from all the availble information on the current day's weather (14 features), and a recurrent neural network (RNN) that examines whether it has rained each day over the past week in order to predict whether it will rain each day of the following week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253e2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# workaround for MacOS/jupyter notebook bug w/ tensorflow\n",
    "# https://www.programmersought.com/article/69923598438/\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f6e48",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "We are once again exploring weather data for the RDU airport in NC's Research Triangle region since  2000, as explored in `data/Data-Wrangling.ipynb` and `data/Data-Visualization.ipynb`. When we import our data, we drop variables that are missing for large portions of the data (`STP` and `GUST`) or likely irrelevant to the data (`DAY`). We add an indicator column (`RAIN`) for whether it has rained that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6056b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4471)\n",
    "# https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "# https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "weather_pd = pd.read_csv('../data/weather.csv', index_col = 0)\n",
    "weather_pd = weather_pd.drop(['DAY', 'STP', 'GUST'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e79c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether it rained that day\n",
    "# bool to int conversion: https://stackoverflow.com/questions/17506163/how-to-convert-a-boolean-array-to-an-int-array\n",
    "weather_pd['RAIN'] = (weather_pd['PRCP'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3541de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>SLP</th>\n",
       "      <th>VISIB</th>\n",
       "      <th>WDSP</th>\n",
       "      <th>MXSPD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNDP</th>\n",
       "      <th>RAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>1023.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>66.9</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1024.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1014.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1019.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>57.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  SEASON  TEMP  DEWP     SLP  VISIB  WDSP  MXSPD   MAX   MIN  \\\n",
       "0  2000      1       0  47.6  38.1  1023.7    8.3   3.0   10.1  66.9  33.1   \n",
       "1  2000      1       0  55.3  46.3  1024.2    9.5   4.8   14.0  70.0  33.1   \n",
       "2  2000      1       0  62.6  55.4  1021.3    8.4   8.5   14.0  73.9  43.0   \n",
       "3  2000      1       0  65.2  58.6  1014.4    9.5  15.3   28.0  73.9  55.0   \n",
       "4  2000      1       0  45.7  30.9  1019.8    9.8   6.4   11.1  57.9  37.0   \n",
       "\n",
       "   PRCP  SNDP  RAIN  \n",
       "0  0.00   0.0     0  \n",
       "1  0.00   0.0     0  \n",
       "2  0.00   0.0     0  \n",
       "3  0.00   0.0     0  \n",
       "4  0.34   0.0     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9941bf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR        int64\n",
       "MONTH       int64\n",
       "SEASON      int64\n",
       "TEMP      float64\n",
       "DEWP      float64\n",
       "SLP       float64\n",
       "VISIB     float64\n",
       "WDSP      float64\n",
       "MXSPD     float64\n",
       "MAX       float64\n",
       "MIN       float64\n",
       "PRCP      float64\n",
       "SNDP      float64\n",
       "RAIN        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b4d11",
   "metadata": {},
   "source": [
    "# Part 1: Today's Weather -> Tomorrow's Rain\n",
    "\n",
    "Our first neural network takes all our known information about today's weather (14 features) and builds a model to predict whether it will rain tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f6323",
   "metadata": {},
   "source": [
    "## Divide into Train/Test Sets\n",
    "\n",
    "We train our model on 90% of the data and test it on the other 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f37e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from original code in project 2\n",
    "def divide_data(weather):\n",
    "    '''divide dataset into two sets: 90% train and 10% test'''\n",
    "    n = weather.shape[0]\n",
    "    \n",
    "    # shuffle data for test/train so no patterns\n",
    "    # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    weather = shuffle(weather)\n",
    "    \n",
    "    # take out 10% of the data for validation\n",
    "    # https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n",
    "    ind_test = np.random.choice(n, size = n // 10, replace = False)\n",
    "    weather_test = weather.iloc[ind_test]\n",
    "\n",
    "    # take the other 90% for building the model\n",
    "    # https://stackoverflow.com/questions/27824075/accessing-numpy-array-elements-not-in-a-given-index-list\n",
    "    ind_train = [x for x in range(n) if x not in ind_test] # not in index\n",
    "    weather_train = weather.iloc[ind_train]\n",
    "\n",
    "    return weather_test, weather_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2383067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  (777, 14)\n",
      "train: (6995, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>SLP</th>\n",
       "      <th>VISIB</th>\n",
       "      <th>WDSP</th>\n",
       "      <th>MXSPD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNDP</th>\n",
       "      <th>RAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>79.5</td>\n",
       "      <td>72.2</td>\n",
       "      <td>1021.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>70.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>84.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1033.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1019.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>59.1</td>\n",
       "      <td>46.5</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>17.1</td>\n",
       "      <td>75.9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      YEAR  MONTH  SEASON  TEMP  DEWP     SLP  VISIB  WDSP  MXSPD   MAX   MIN  \\\n",
       "1303  2003      7       2  79.5  72.2  1021.6    9.4   6.2   13.0  90.0  69.1   \n",
       "3355  2009      3       0  70.8  41.4  1015.0   10.0   9.7   15.9  84.0  53.1   \n",
       "52    2000      2       0  39.9  28.0  1033.2    8.9   1.1    8.0  57.0  27.0   \n",
       "2575  2007      1       0  40.6  32.0  1019.2    4.6   5.1   11.1  54.0  27.1   \n",
       "705   2001     12       3  59.1  46.5  1025.2    9.9   4.9   17.1  75.9  36.0   \n",
       "\n",
       "      PRCP  SNDP  RAIN  \n",
       "1303  0.02   0.0     1  \n",
       "3355  0.00   0.0     0  \n",
       "52    0.00   0.0     0  \n",
       "2575  0.23   0.0     1  \n",
       "705   0.00   0.0     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_test, weather_train = divide_data(weather_pd)\n",
    "print(\"test: \", weather_test.shape)\n",
    "print(\"train:\", weather_train.shape)\n",
    "weather_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b4908",
   "metadata": {},
   "source": [
    "## Divide Each Set into Features/Targets\n",
    "\n",
    "For both the training set and testing set, our predictive features are the current day's weather, and the target output is whether it will rain tomorrow. Thus, we shift the target values over by one index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf80642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_targets(weather):\n",
    "    '''separate dataset into features and targets'''\n",
    "    # target: whether next day rains\n",
    "    target = weather[['RAIN']].iloc[1:, :]\n",
    "    target = np.round(target.to_numpy().reshape(-1))\n",
    "\n",
    "    # feature: today's weather (array of 14 vars)\n",
    "    feature = weather.iloc[:-1].to_numpy()\n",
    "    \n",
    "    return feature, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75762628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: (776, 14) target: (776,)\n",
      "feature: (6994, 14) target: (6994,)\n"
     ]
    }
   ],
   "source": [
    "feature_test, target_test = separate_targets(weather_test)\n",
    "feature_train, target_train = separate_targets(weather_train)\n",
    "\n",
    "print(\"feature:\", feature_test.shape, \"target:\", target_test.shape)\n",
    "print(\"feature:\", feature_train.shape, \"target:\", target_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ea51e",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "Our neural network has an input layer (not shown), a hidden layer, and an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817a040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many possible outputs\n",
    "num_output_vals = len(np.unique(target_test))\n",
    "\n",
    "# num nodes in first layer\n",
    "first_layer = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fb0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(first_layer, num_output_vals):\n",
    "    ''' build NN model'''\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(first_layer, activation='sigmoid', dtype='float64'),\n",
    "        tf.keras.layers.Dropout(0.2, dtype='float64'),\n",
    "        tf.keras.layers.Dense(num_output_vals, activation='sigmoid', dtype='float64')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56867f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(first_layer, num_output_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384e929",
   "metadata": {},
   "source": [
    "## Example Model Output\n",
    "\n",
    "As an example, we can apply our model to a day of weather from the training dataset. We observe that the model output has two values, corresponding with our two possible outcomes: dry or rainy. These results will not be accurate because we have not yet trained our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2162b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = model(feature_train[88].reshape(1,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fd15547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef5c3623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=57, shape=(1, 2), dtype=float64, numpy=array([[0.59816531, 0.41840464]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e911112",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Next, we train the model on our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36aecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e405ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6994 samples\n",
      "Epoch 1/30\n",
      "6994/6994 [==============================] - 1s 145us/sample - loss: 0.6624 - accuracy: 0.6313\n",
      "Epoch 2/30\n",
      "6994/6994 [==============================] - 0s 56us/sample - loss: 0.6611 - accuracy: 0.6358\n",
      "Epoch 3/30\n",
      "6994/6994 [==============================] - 0s 55us/sample - loss: 0.6583 - accuracy: 0.6365\n",
      "Epoch 4/30\n",
      "6994/6994 [==============================] - 0s 55us/sample - loss: 0.6571 - accuracy: 0.6370\n",
      "Epoch 5/30\n",
      "6994/6994 [==============================] - 0s 56us/sample - loss: 0.6572 - accuracy: 0.6367\n",
      "Epoch 6/30\n",
      "6994/6994 [==============================] - 0s 55us/sample - loss: 0.6584 - accuracy: 0.6367\n",
      "Epoch 7/30\n",
      "6994/6994 [==============================] - 0s 55us/sample - loss: 0.6576 - accuracy: 0.6367\n",
      "Epoch 8/30\n",
      "6994/6994 [==============================] - 0s 55us/sample - loss: 0.6573 - accuracy: 0.6367\n",
      "Epoch 9/30\n",
      "6994/6994 [==============================] - 0s 59us/sample - loss: 0.6571 - accuracy: 0.6367\n",
      "Epoch 10/30\n",
      "6994/6994 [==============================] - 0s 56us/sample - loss: 0.6570 - accuracy: 0.6367\n",
      "Epoch 11/30\n",
      "6994/6994 [==============================] - 0s 58us/sample - loss: 0.6578 - accuracy: 0.6367\n",
      "Epoch 12/30\n",
      "6994/6994 [==============================] - 0s 57us/sample - loss: 0.6570 - accuracy: 0.6367\n",
      "Epoch 13/30\n",
      "6994/6994 [==============================] - 0s 56us/sample - loss: 0.6562 - accuracy: 0.6367\n",
      "Epoch 14/30\n",
      "6994/6994 [==============================] - 0s 57us/sample - loss: 0.6567 - accuracy: 0.6367\n",
      "Epoch 15/30\n",
      "6994/6994 [==============================] - 0s 56us/sample - loss: 0.6565 - accuracy: 0.6367\n",
      "Epoch 16/30\n",
      "6994/6994 [==============================] - 0s 56us/sample - loss: 0.6568 - accuracy: 0.6367\n",
      "Epoch 17/30\n",
      "6994/6994 [==============================] - 0s 56us/sample - loss: 0.6561 - accuracy: 0.6367\n",
      "Epoch 18/30\n",
      "6994/6994 [==============================] - 0s 56us/sample - loss: 0.6566 - accuracy: 0.6367\n",
      "Epoch 19/30\n",
      "6994/6994 [==============================] - 0s 58us/sample - loss: 0.6556 - accuracy: 0.6367\n",
      "Epoch 20/30\n",
      "6994/6994 [==============================] - 0s 57us/sample - loss: 0.6557 - accuracy: 0.6367\n",
      "Epoch 21/30\n",
      "6994/6994 [==============================] - 0s 58us/sample - loss: 0.6566 - accuracy: 0.6367\n",
      "Epoch 22/30\n",
      "6994/6994 [==============================] - 0s 60us/sample - loss: 0.6556 - accuracy: 0.6367\n",
      "Epoch 23/30\n",
      "6994/6994 [==============================] - 0s 61us/sample - loss: 0.6559 - accuracy: 0.6367\n",
      "Epoch 24/30\n",
      "6994/6994 [==============================] - 0s 64us/sample - loss: 0.6553 - accuracy: 0.6367\n",
      "Epoch 25/30\n",
      "6994/6994 [==============================] - 0s 60us/sample - loss: 0.6562 - accuracy: 0.6367\n",
      "Epoch 26/30\n",
      "6994/6994 [==============================] - 0s 61us/sample - loss: 0.6560 - accuracy: 0.6367\n",
      "Epoch 27/30\n",
      "6994/6994 [==============================] - 0s 65us/sample - loss: 0.6553 - accuracy: 0.6367\n",
      "Epoch 28/30\n",
      "6994/6994 [==============================] - 1s 80us/sample - loss: 0.6558 - accuracy: 0.6367\n",
      "Epoch 29/30\n",
      "6994/6994 [==============================] - 1s 77us/sample - loss: 0.6555 - accuracy: 0.6367\n",
      "Epoch 30/30\n",
      "6994/6994 [==============================] - 0s 63us/sample - loss: 0.6559 - accuracy: 0.6367\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(feature_train, target_train, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc1d5853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  960       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  130       \n",
      "=================================================================\n",
      "Total params: 1,090\n",
      "Trainable params: 1,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff1a48",
   "metadata": {},
   "source": [
    "## Predict for an Example Day\n",
    "\n",
    "Now that the model is trained, we can predict whether it will rain tomorrow for any day in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def2c752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.588809437302793\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(feature_test[88].reshape(1,14))\n",
    "print(sum(sum(pred)))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6beb2f8",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set\n",
    "\n",
    "Finally, we can evaluate the performance of our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84f8e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/1 - 0s - loss: 0.7206 - accuracy: 0.6392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6544783852764011, 0.63917524]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(feature_test, target_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32323b",
   "metadata": {},
   "source": [
    "We obtain a somewhat inaccurate accuracy of 64%. This is to be expected, since the weather can change rapidly in 24 hours. Additionally, this model has very little sense of movement through time, so it cannot learn general weather trends outside a 24-hour period. Below, we explore using a recurrent neural network harness the sequential nature of our weather datain our modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d561e",
   "metadata": {},
   "source": [
    "# Part 2: Last Week's Rain -> This Week's Rain\n",
    "\n",
    "Our second neural network takes the pattern of rain over the past week and predicts whether it will rain the following day. This neural network is a recurrent neural network (RNN) because we can run this model iteratively, reusing our predictions as inputs, to generate rain predictions for the entire next week of weather."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c2061",
   "metadata": {},
   "source": [
    "## Create Features and Targets\n",
    "\n",
    "For this neural network, we will only use the `RAIN` column of our weather data, which indicates whether or not it rained on a particular day.\n",
    "\n",
    "The following code prepares weeks of data on which to train our RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7e17c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7772,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract rain column\n",
    "rain = weather_pd[['RAIN']].to_numpy().reshape(-1)\n",
    "rain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b14bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# week length\n",
    "seq_length = 7\n",
    "examples_per_epoch = len(rain)//(seq_length+1)\n",
    "\n",
    "# convert to tf\n",
    "rain_tf = tf.data.Dataset.from_tensor_slices(rain)\n",
    "\n",
    "# example data\n",
    "for i in rain_tf.take(5):\n",
    "  print(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de2a77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 1 1]\n",
      "[1 1 1 0 0 0 0 0]\n",
      "[0 1 1 1 0 0 1 1]\n",
      "[1 1 0 0 0 1 1 0]\n",
      "[0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# turn individual days into week sequences\n",
    "weeks = rain_tf.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for day in weeks.take(5):\n",
    "  print(day.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e337562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input week is days 0-6, target week is days 1-7\n",
    "def split_input_target(week):\n",
    "    '''duplicate and shift weeks to form input and target days'''\n",
    "    input_days = week[:-1]\n",
    "    target_days = week[1:]\n",
    "    return input_days, target_days\n",
    "\n",
    "dataset = weeks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f37f1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  [0 0 0 0 1 0 1]\n",
      "Target data: [0 0 0 1 0 1 1]\n",
      "Input data:  [1 1 1 0 0 0 0]\n",
      "Target data: [1 1 0 0 0 0 0]\n",
      "Input data:  [0 1 1 1 0 0 1]\n",
      "Target data: [1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# view example inputs and targets\n",
    "for input_example, target_example in  dataset.take(3):\n",
    "    print ('Input data: ', input_example.numpy())\n",
    "    print ('Target data:', target_example.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3afccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 0\n",
      "  expected output: 1\n",
      "Step    1\n",
      "  input: 1\n",
      "  expected output: 1\n",
      "Step    2\n",
      "  input: 1\n",
      "  expected output: 1\n",
      "Step    3\n",
      "  input: 1\n",
      "  expected output: 0\n",
      "Step    4\n",
      "  input: 0\n",
      "  expected output: 0\n"
     ]
    }
   ],
   "source": [
    "# view example input and output\n",
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input:\", input_idx.numpy())\n",
    "    print(\"  expected output:\", target_idx.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88c26f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((4, 7), (4, 7)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training batches of size 4\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# buffer size to shuffle dataset\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1f908",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "We build our recurrent neural network with an embedding layer to process our inputs, a recurrent hidden layer, and an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50a74bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many possible outputs\n",
    "num_output_vals = len(np.unique(rain))\n",
    "\n",
    "# embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# number of RNN units\n",
    "rnn_units = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ac874e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_RNN(num_output_vals, embedding_dim, rnn_units, batch_size):\n",
    "    '''build an RNN'''\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(num_output_vals, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(num_output_vals)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8da02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRNN = build_model_RNN(num_output_vals, embedding_dim, rnn_units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea851a",
   "metadata": {},
   "source": [
    "## Example Model Output\n",
    "\n",
    "As an example, we can apply our model to a day of weather from the training dataset. We observe that the model output comes in batches of 4 weeks, each 7 days long, with two possible output states of raining or not raining.\n",
    "\n",
    "These results will not be accurate because we have not yet trained our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f194e1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 2) # (batch_size, sequence_length, num_output_vals)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = modelRNN(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, num_output_vals)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c0f4b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example prediction\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ed4fd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " [0 0 1 1 1 1 1]\n",
      "\n",
      "Next Day Predictions: \n",
      " [1 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# show input and output\n",
    "print(\"Input: \\n\", input_example_batch[0].numpy())\n",
    "print()\n",
    "print(\"Next Day Predictions: \\n\", sampled_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46545a7",
   "metadata": {},
   "source": [
    "## Prepare Model for Training\n",
    "\n",
    "Now that we have applied our model to at least one dataset, we can view the structure of our neural network. We also need to compile our model and configure checkpoints to save our training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c62177e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (4, None, 256)            512       \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (4, None, 16)             13152     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (4, None, 2)              34        \n",
      "=================================================================\n",
      "Total params: 13,698\n",
      "Trainable params: 13,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb1af93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (4, 7, 2)  # (batch_size, days_in_batches, num_output_vals)\n",
      "Mean loss:         0.691676\n"
     ]
    }
   ],
   "source": [
    "# set up loss function\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, days_in_batches, num_output_vals)\")\n",
    "print(\"Mean loss:        \", mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a82f0e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9970598"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exponential of the mean loss should ~= num outputs\n",
    "tf.exp(mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce3880",
   "metadata": {},
   "source": [
    "As we configure our loss function, we notice that the exponential of the mean loss is about equal to the number of outputs, which indicates that the model should not be overconfident about wrong predictions—a good sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32b80bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "modelRNN.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "533ccb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure checkpoints to save during training\n",
    "# directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training-checkpoints'\n",
    "# name checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336d888",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Now, our model is ready to be trained on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e128493",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0475bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.6206\n",
      "Epoch 2/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6136\n",
      "Epoch 3/30\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.6122\n",
      "Epoch 4/30\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.6121\n",
      "Epoch 5/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6108\n",
      "Epoch 6/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6115\n",
      "Epoch 7/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6110\n",
      "Epoch 8/30\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6114\n",
      "Epoch 9/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6093\n",
      "Epoch 10/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6108\n",
      "Epoch 11/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6107\n",
      "Epoch 12/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6108\n",
      "Epoch 13/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6109\n",
      "Epoch 14/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6115\n",
      "Epoch 15/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6114\n",
      "Epoch 16/30\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6110\n",
      "Epoch 17/30\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6124\n",
      "Epoch 18/30\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6112\n",
      "Epoch 19/30\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6107\n",
      "Epoch 20/30\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6106\n",
      "Epoch 21/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6111\n",
      "Epoch 22/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6117\n",
      "Epoch 23/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6103\n",
      "Epoch 24/30\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6106\n",
      "Epoch 25/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6112\n",
      "Epoch 26/30\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6113\n",
      "Epoch 27/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6124\n",
      "Epoch 28/30\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6102\n",
      "Epoch 29/30\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.6106\n",
      "Epoch 30/30\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6102\n"
     ]
    }
   ],
   "source": [
    "history = modelRNN.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62bcf61",
   "metadata": {},
   "source": [
    "## Restore Latest Checkpoint\n",
    "\n",
    "Since we saved the checkpoints of our model, we do not need to re-train the model every time we open this notebook. We can restore the model from our last checkpoint, this time with a batch size of 1, to obtain a complete model that is ready to make predictions for any given week of rain patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b85de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            512       \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 16)             13152     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 2)              34        \n",
      "=================================================================\n",
      "Total params: 13,698\n",
      "Trainable params: 13,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def restore_model(num_output_vals, embedding_dim, rnn_units):\n",
    "    '''restore model from save'''\n",
    "    tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "    modelRNN = build_model_RNN(num_output_vals, embedding_dim, rnn_units, batch_size=1)\n",
    "    modelRNN.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    modelRNN.build(tf.TensorShape([1, None]))\n",
    "    \n",
    "    return modelRNN\n",
    "\n",
    "modelRNN = restore_model(num_output_vals, embedding_dim, rnn_units)\n",
    "\n",
    "modelRNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ca3b0",
   "metadata": {},
   "source": [
    "## Generate Rain Predictions for Next Week\n",
    "\n",
    "Now we can evaluate our model by generating rain predictions for next week! Starting with whether it has rained over each of the past seven days, our model will predict whether it will rain tomorrow. Then, assuming tomorrow is the current day, our model will predict whether it will rain the following day, and so on. Like a real weather forecast, this will likely get less accurate the further out we predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cadb5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example week - it has not rained in the past 7 days\n",
    "# as of May 20, 2021\n",
    "example_week = np.array([[0, 0, 0, 0, 0, 0, 0]])\n",
    "example_week.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d880a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weather(model, start_weather):\n",
    "    '''generate rain predictions for the next 7 days'''\n",
    "    # Evaluation step (generating weather using the learned model)\n",
    "\n",
    "    # Number of days to generate\n",
    "    num_generate = 7\n",
    "\n",
    "    # Empty string to store our results\n",
    "    days_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable results.\n",
    "    # Higher temperatures results in more surprising results.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(start_weather)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the temperature returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        # we pass the predicted weather as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        start_weather = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        days_generated.append(predicted_id)\n",
    "\n",
    "    return days_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b54397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start days:          [0, 0, 0, 0, 0, 0, 0]\n",
      "predicted next days: [0, 0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"start days:         \", list(example_week[0]))\n",
    "print(\"predicted next days:\", generate_weather(modelRNN, start_weather=example_week))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca28b2a",
   "metadata": {},
   "source": [
    "This RNN predicts that it will be clear for the next 7 days except for 5 days from now. Currently, my weather app (Dark Sky) is predicting clear weather most of this week with about a 50% chance of rain 5 and 7 days from now - fairly close to what my model predicts! This could easily be by chance, since weather forecasting is fairly inaccurate so far out. However, these results are encouraging that the model would expect a couple days of rain after so many clear days, which is a very normal weather pattern for North Carolina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afea7c9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It seems unlikely that either of these neural networks is extremely accurate, since we are only building from the most common weather features, on data from only the past two decades, from one single location in North Carolina. In practice, meteorology is surely much more complicated than throwing some weather data at a neural network and seeing what pops out. However, for this portfolio project, both models achieved encouraging results. The first model may have only been 64% accurate, but 64% is better than random chance. And the results our RNN  generated are fairly similar to my weather app's current forecast, an encouraging sign that it started to learn North Carolina's weather trends.\n",
    "\n",
    "In future work, I would like to explore whether feeding more data into these neural networks could produce more accurate results. In the first neural network, I could try predicting whether it will rain tomorrow based off all the weather features of the past week, rather than just the weather features of the current day. In the RNN, I could explore different training sequence sizes and batch sizes for learning North Carolina's rain trends. There certainly is plenty more I would like to explore with deep learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
